{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24a975d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "from seqeval.metrics import classification_report, f1_score, accuracy_score\n",
    "from sklearn.metrics import accuracy_score as sk_accuracy_score, classification_report as sk_classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0439105",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\"O\": 0, \"B-ASP\": 1, \"I-ASP\": 2}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "sentiment2id = {\n",
    "    \"negative\": 0,\n",
    "    \"positive\": 1,\n",
    "    \"neutral\": 2\n",
    "}\n",
    "id2sentiment = {v: k for k, v in sentiment2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22cc887e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pl.read_parquet(\"../data/processed/df_aspect_pos.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "763c6f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids',\n",
       " 'attention_mask',\n",
       " 'labels',\n",
       " 'aspects_index',\n",
       " 'aspects_sentiment',\n",
       " 'type']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1fdda69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    input_ids = torch.stack([item[\"input_ids\"] for item in batch])\n",
    "    attention_mask = torch.stack([item[\"attention_mask\"] for item in batch])\n",
    "    labels = torch.stack([item[\"labels\"] for item in batch])\n",
    "\n",
    "    aspects_index = [item[\"aspects_index\"] for item in batch]          # List[List[List[int]]]\n",
    "    aspects_sentiment = [item[\"aspects_sentiment\"] for item in batch]  # List[List[int]]\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels,\n",
    "        \"aspects_index\": aspects_index,\n",
    "        \"aspects_sentiment\": aspects_sentiment,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ef7f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_aspect_spans(pred_labels):\n",
    "    spans = []\n",
    "    i = 0\n",
    "    while i < len(pred_labels):\n",
    "        if pred_labels[i] == 1:  # B-ASP\n",
    "            start = i\n",
    "            i += 1\n",
    "            while i < len(pred_labels) and pred_labels[i] == 2:  # I-ASP\n",
    "                i += 1\n",
    "            end = i - 1\n",
    "            spans.append([start, end])\n",
    "        else:\n",
    "            i += 1\n",
    "    return spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d3d111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.input_ids = df[\"input_ids\"].to_numpy()\n",
    "        self.attention_mask = df[\"attention_mask\"].to_numpy()\n",
    "        self.labels = df[\"labels\"].to_numpy()\n",
    "        self.aspects_index = df[\"aspects_index\"].to_list()\n",
    "        self.aspects_sentiment = df[\"aspects_sentiment\"].to_list()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(self.input_ids[idx], dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(self.attention_mask[idx], dtype=torch.long),\n",
    "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long),\n",
    "            \"aspects_index\": self.aspects_index[idx],           # list of [start, end]\n",
    "            \"aspects_sentiment\": self.aspects_sentiment[idx],   # list of sentiment values\n",
    "        }\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = CustomDataset(df.filter(pl.col(\"type\") != \"val\"))\n",
    "val_dataset = CustomDataset(df.filter(pl.col(\"type\") == \"val\"))\n",
    "test_dataset = CustomDataset(df.filter(pl.col(\"type\") == \"test\"))\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size , collate_fn=custom_collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=custom_collate_fn)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d15b8f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "[[1, 1, 1], [0], [1, 2, 2, 1], [0, 1, 0, 2, 2], [1, 1], [1], [1], [0], [1], [0, 0, 0], [1], [1], [1], [1], [0], [0], [0], [0], [1], [1], [1], [1], [1], [1, 1], [1, 0], [1, 0], [1, 1], [1], [1], [0], [1], [1]]\n",
      "[[[2, 2], [5, 5], [8, 8]], [[1, 1]], [[1, 1], [8, 8], [23, 23], [19, 20]], [[15, 16], [10, 10], [22, 22], [29, 29], [35, 35]], [[3, 5], [33, 35]], [[9, 9]], [[13, 13]], [[6, 9]], [[6, 8]], [[7, 9], [11, 14], [16, 19]], [[7, 7]], [[10, 10]], [[2, 2]], [[2, 2]], [[2, 2]], [[7, 7]], [[1, 2]], [[1, 2]], [[3, 4]], [[2, 2]], [[10, 14]], [[7, 12]], [[5, 5]], [[5, 6], [12, 12]], [[4, 5], [9, 9]], [[3, 3], [15, 15]], [[21, 21], [4, 5]], [[5, 5]], [[3, 3]], [[3, 4]], [[8, 8]], [[3, 4]]]\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(batch[\"input_ids\"].shape)\n",
    "    print(batch[\"attention_mask\"].shape)\n",
    "    print(batch[\"labels\"].shape)\n",
    "    print(batch[\"aspects_sentiment\"])\n",
    "    print(batch[\"aspects_index\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "769844cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AspectDetectionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AspectDetectionModel, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, len(label2id))\n",
    "        self.sentiment_classifier = nn.Linear(self.bert.config.hidden_size, 3)  # positive, negative, neutral\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = self.dropout(outputs.last_hidden_state)  # [B, L, H]\n",
    "        logits = self.classifier(sequence_output)  # [B, L, num_labels]\n",
    "        return logits, sequence_output\n",
    "\n",
    "model = AspectDetectionModel().to(\"mps\")\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "optimizer = optimizer = torch.optim.AdamW([\n",
    "    {'params': model.bert.parameters(), 'lr': 2e-5},\n",
    "    {'params': model.classifier.parameters(), 'lr': 5e-5},\n",
    "    {'params': model.sentiment_classifier.parameters(), 'lr': 5e-5}\n",
    "])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6075974f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Aspect Loss: 0.2662, Train Sentiment Loss: 0.4474, Val Aspect Loss: 0.1475, Val Sentiment Loss: 0.2836\n",
      "Epoch [2/10], Train Aspect Loss: 0.1279, Train Sentiment Loss: 0.2362, Val Aspect Loss: 0.1201, Val Sentiment Loss: 0.2555\n",
      "Epoch [3/10], Train Aspect Loss: 0.1013, Train Sentiment Loss: 0.1403, Val Aspect Loss: 0.1201, Val Sentiment Loss: 0.3346\n",
      "Epoch [4/10], Train Aspect Loss: 0.0857, Train Sentiment Loss: 0.0852, Val Aspect Loss: 0.1247, Val Sentiment Loss: 0.4020\n",
      "Epoch [5/10], Train Aspect Loss: 0.0739, Train Sentiment Loss: 0.0503, Val Aspect Loss: 0.1210, Val Sentiment Loss: 0.3956\n",
      "Epoch [6/10], Train Aspect Loss: 0.0638, Train Sentiment Loss: 0.0377, Val Aspect Loss: 0.1159, Val Sentiment Loss: 0.3694\n",
      "Epoch [7/10], Train Aspect Loss: 0.0550, Train Sentiment Loss: 0.0262, Val Aspect Loss: 0.1210, Val Sentiment Loss: 0.3920\n",
      "Epoch [8/10], Train Aspect Loss: 0.0477, Train Sentiment Loss: 0.0193, Val Aspect Loss: 0.1294, Val Sentiment Loss: 0.4170\n",
      "Epoch [9/10], Train Aspect Loss: 0.0426, Train Sentiment Loss: 0.0180, Val Aspect Loss: 0.1371, Val Sentiment Loss: 0.4224\n",
      "Epoch [10/10], Train Aspect Loss: 0.0383, Train Sentiment Loss: 0.0140, Val Aspect Loss: 0.1372, Val Sentiment Loss: 0.4341\n",
      "Aspect Extraction Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ASP       0.76      0.83      0.79     11700\n",
      "\n",
      "   micro avg       0.76      0.83      0.79     11700\n",
      "   macro avg       0.76      0.83      0.79     11700\n",
      "weighted avg       0.76      0.83      0.79     11700\n",
      "\n",
      "Aspect F1: 0.7944378746482893\n",
      "Sentiment Classification Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89      2329\n",
      "           1       0.94      0.97      0.96      6686\n",
      "           2       0.61      0.42      0.50       667\n",
      "\n",
      "    accuracy                           0.91      9682\n",
      "   macro avg       0.82      0.76      0.78      9682\n",
      "weighted avg       0.91      0.91      0.91      9682\n",
      "\n",
      "Sentiment Accuracy: 0.9133443503408387\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "true_tags = []\n",
    "pred_tags = []\n",
    "true_sentiments = []\n",
    "pred_sentiments = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_aspect_train_loss = 0\n",
    "    total_sentiment_train_loss = 0\n",
    "    total_aspect_val_loss = 0\n",
    "    total_sentiment_val_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        input_ids = batch[\"input_ids\"].to(\"mps\")\n",
    "        attention_mask = batch[\"attention_mask\"].to(\"mps\")\n",
    "        labels = batch[\"labels\"].to(\"mps\")\n",
    "\n",
    "        # logits contains the aspect extraction head output and sequence_output contains the contextualized embeddings\n",
    "        logits, sequence_output = model(input_ids, attention_mask)\n",
    "        aspect_loss = criterion(logits.view(-1, len(label2id)), labels.view(-1))\n",
    "        total_aspect_train_loss += aspect_loss.item()\n",
    "\n",
    "        sentiment_losses = []\n",
    "        for i in range(len(input_ids)):\n",
    "            for aspect_index, sentiment in zip(batch[\"aspects_index\"][i], batch[\"aspects_sentiment\"][i]):\n",
    "                if aspect_index[1] >= sequence_output.size(1):\n",
    "                    continue\n",
    "                # Assume the aspect span is a list of words ['chrome', '##book'], BIO tags are ['B-ASP', 'I-ASP'], and indices are [15, 16]\n",
    "                # Each word in the aspect span have its own embedding in the sequence output\n",
    "                # We take the mean of the embeddings for the aspect span\n",
    "                # aspect_index = [15, 16] means we take the mean of sequence_output[i, 15:17]\n",
    "                pooled = sequence_output[i, aspect_index[0]:aspect_index[1]+1].mean(dim=0)\n",
    "                sentiment_logits = model.sentiment_classifier(pooled.unsqueeze(0))\n",
    "                sentiment_target = torch.tensor([sentiment], dtype=torch.long).to(\"mps\")\n",
    "                sentiment_loss = criterion(sentiment_logits.view(-1, 3), sentiment_target)\n",
    "                sentiment_losses.append(sentiment_loss)\n",
    "\n",
    "\n",
    "        if sentiment_losses:\n",
    "            sentiment_loss = torch.stack(sentiment_losses).mean()\n",
    "        else:\n",
    "            sentiment_loss = torch.tensor(0.0).to(\"mps\")\n",
    "\n",
    "        total_sentiment_train_loss += sentiment_loss.item()\n",
    "        total_loss = aspect_loss + sentiment_loss\n",
    "\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        for batch in val_dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(\"mps\")\n",
    "            attention_mask = batch[\"attention_mask\"].to(\"mps\")\n",
    "            labels = batch[\"labels\"].to(\"mps\")\n",
    "\n",
    "            logits, sequence_output = model(input_ids, attention_mask)\n",
    "            aspect_loss = criterion(logits.view(-1, len(label2id)), labels.view(-1))\n",
    "            total_aspect_val_loss += aspect_loss.item()\n",
    "\n",
    "            sentiment_losses = []\n",
    "            preds = torch.argmax(logits, dim=2)\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "\n",
    "            for true, pred in zip(labels.cpu().numpy(), preds):\n",
    "                filtered_true = []\n",
    "                filtered_pred = []\n",
    "                for t, p in zip(true, pred):\n",
    "                    if t != -100:\n",
    "                        filtered_true.append(id2label[t])\n",
    "                        filtered_pred.append(id2label[p])\n",
    "                true_tags.append(filtered_true)\n",
    "                pred_tags.append(filtered_pred)\n",
    "\n",
    "            for i in range(len(input_ids)):\n",
    "                # During training, I used the existing aspect spans from the training data. But during evaluation, \n",
    "                # I will extract the aspect spans from the predicted labels\n",
    "                # This is because the aspect spans are not available in the validation data\n",
    "                # I will use the predicted labels to extract the aspect spans\n",
    "                # The predicted labels are in the form of BIO tags \n",
    "                aspects = extract_aspect_spans(preds[i])\n",
    "                for aspect_index, sentiment in zip(batch[\"aspects_index\"][i], batch[\"aspects_sentiment\"][i]):\n",
    "                    if aspect_index in aspects and aspect_index[1] < sequence_output.size(1):\n",
    "                        pooled = sequence_output[i, aspect_index[0]:aspect_index[1]+1].mean(dim=0)\n",
    "                        sentiment_logits = model.sentiment_classifier(pooled.unsqueeze(0))\n",
    "                        sentiment_target = torch.tensor([sentiment], dtype=torch.long).to(\"mps\")\n",
    "                        sentiment_loss = criterion(sentiment_logits.view(-1, 3), sentiment_target)\n",
    "                        sentiment_losses.append(sentiment_loss)\n",
    "                        pred_sentiments.append(sentiment_logits.argmax(dim=-1).item())\n",
    "                        true_sentiments.append(sentiment)\n",
    "\n",
    "            if sentiment_losses:\n",
    "                sentiment_loss = torch.stack(sentiment_losses).mean()\n",
    "            else:\n",
    "                sentiment_loss = torch.tensor(0.0).to(\"mps\")\n",
    "\n",
    "            total_sentiment_val_loss += sentiment_loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "        f\"Train Aspect Loss: {total_aspect_train_loss/len(train_dataloader):.4f}, \"\n",
    "        f\"Train Sentiment Loss: {total_sentiment_train_loss/len(train_dataloader):.4f}, \"\n",
    "        f\"Val Aspect Loss: {total_aspect_val_loss/len(val_dataloader):.4f}, \"\n",
    "        f\"Val Sentiment Loss: {total_sentiment_val_loss/len(val_dataloader):.4f}\")\n",
    "\n",
    "print(\"Aspect Extraction Metrics:\")\n",
    "print(classification_report(true_tags, pred_tags))\n",
    "print(\"Aspect F1:\", f1_score(true_tags, pred_tags))\n",
    "\n",
    "print(\"Sentiment Classification Metrics:\")\n",
    "print(sk_classification_report(true_sentiments, pred_sentiments))\n",
    "print(\"Sentiment Accuracy:\", sk_accuracy_score(true_sentiments, pred_sentiments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e18f56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully to ../models/AspectDetectionModel/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "name=\"AspectDetectionModel_Sentiment_Analysis\"\n",
    "\n",
    "os.makedirs(\"../models/AspectDetectionModel\", exist_ok=True)\n",
    "\n",
    "torch.save(model.state_dict(), \"../models/AspectDetectionModel/\" + name + \".pth\")\n",
    "\n",
    "model_config = {\n",
    "\t\"hidden_size\": model.bert.config.hidden_size,\n",
    "\t\"num_labels\": len(label2id),\n",
    "\t\"id2label\": id2label,\n",
    "\t\"label2id\": label2id,\n",
    "\t\"name\": name\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(f\"../models/AspectDetectionModel/{name}_config.json\", \"w\") as f:\n",
    "\tjson.dump(model_config, f)\n",
    "\n",
    "print(\"Model saved successfully to ../models/AspectDetectionModel/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07c62198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AspectDetectionModel(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (sentiment_classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=\"AspectDetectionModel_Sentiment_Analysis\"\n",
    "model = AspectDetectionModel()\n",
    "model.load_state_dict(torch.load(\"../models/AspectDetectionModel/\" + name + \".pth\"))\n",
    "model = model.to(\"mps\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee4af7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 1996, 2152, 7597, 2017, 1005, 2128, 2183, 2000, 3477, 2003, 2005, 1996, 3193, 2025, 2005, 1996, 2833, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "temp = tokenizer((\"\"\"the high prices you ' re going to pay is for the view not for the food .\"\"\").split(), is_split_into_words=True,\n",
    "                          truncation=True,\n",
    "                          padding=\"max_length\",\n",
    "                          max_length=128)\n",
    "\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0773bacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2023, 6556, 2491, 2482, 2003, 4569, 1010, 3435, 1010, 1998, 3733, 2000, 5047, 1517, 3819, 2005, 4268, 999, 1996, 3857, 3737, 2003, 23073, 1998, 2009, 3216, 15299, 2006, 2367, 9972, 1012, 6046, 2166, 2003, 11519, 1998, 1996, 7711, 2024, 2200, 26651, 1012, 1037, 2307, 5592, 2005, 4268, 999, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "temp = tokenizer((\"\"\"This remote control car is fun, fast, and easy to handleâ€”perfect for kids! The build quality is sturdy and it runs smoothly on different surfaces. Battery life is decent and the controls are very responsive. A great gift for kids!\"\"\").split(), is_split_into_words=True,\n",
    "                          truncation=True,\n",
    "                          padding=\"max_length\",\n",
    "                          max_length=128)\n",
    "\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b6d752c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2482, 3737, 2003, 2200, 3835, 2021, 1996, 11486, 19237, 1012, 1996, 11486, 1997, 2023, 2482, 2079, 2025, 2573, 7919, 1998, 1996, 2345, 1999, 1996, 11486, 2079, 2025, 24357, 3929, 2009, 2069, 24357, 2066, 6462, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "temp = tokenizer((\"\"\"Car quality is very nice but the controller sucks . The controller of this car do not works properly and the final in the controller do not rotate fully it only rotate like button\"\"\").split(), is_split_into_words=True,\n",
    "                          truncation=True,\n",
    "                          padding=\"max_length\",\n",
    "                          max_length=128)\n",
    "\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28521159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 2, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 1, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0], device='mps:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=\"mps\"\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\n",
    "    \n",
    "    input_ids = torch.tensor(temp[\"input_ids\"], dtype=torch.long).unsqueeze(0).to(device)\n",
    "    attention_mask = torch.tensor(temp[\"attention_mask\"], dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    logits, sequence_output = model(input_ids, attention_mask)\n",
    "    # decode the logits to get the predicted labels\n",
    "    preds = torch.argmax(logits, dim=2)[0]\n",
    "    aspects = extract_aspect_spans(preds.cpu().tolist())\n",
    "    sentiments=[]\n",
    "\n",
    "\n",
    "    for aspect in aspects:\n",
    "        pooled = sequence_output[0, aspect[0]:aspect[1]+1].mean(dim=0)\n",
    "        sentiment_logits = model.sentiment_classifier(\n",
    "            pooled.unsqueeze(0)\n",
    "        )\n",
    "        sentiments.append({\"pos\":aspect,\"senti\":torch.argmax(sentiment_logits, dim=1).item()})\n",
    "\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "000e9f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.8200e+00, -5.2799e-01, -3.2160e+00],\n",
       "         [ 9.7274e-01,  2.4056e+00, -3.9802e+00],\n",
       "         [ 4.5306e-01, -2.9232e+00,  2.0572e+00],\n",
       "         [ 5.9108e+00, -2.5656e+00, -3.7683e+00],\n",
       "         [ 6.4181e+00, -2.5217e+00, -4.2056e+00],\n",
       "         [ 5.9672e+00, -2.2473e+00, -4.2224e+00],\n",
       "         [ 7.1839e+00, -3.1137e+00, -4.0946e+00],\n",
       "         [ 6.1606e+00, -2.8793e+00, -3.6381e+00],\n",
       "         [-7.0848e-01,  3.4834e+00, -2.2773e+00],\n",
       "         [ 6.2572e+00, -3.4404e+00, -3.1373e+00],\n",
       "         [ 6.5763e+00, -2.8340e+00, -3.6271e+00],\n",
       "         [ 5.6258e+00, -2.7777e+00, -3.3384e+00],\n",
       "         [-9.3669e-01,  3.0684e+00, -1.7020e+00],\n",
       "         [ 3.0925e+00, -3.8961e+00,  1.7643e-01],\n",
       "         [ 5.8309e+00, -3.6962e+00, -3.1830e+00],\n",
       "         [ 3.4539e+00, -1.1128e+00, -2.3963e+00],\n",
       "         [ 6.1784e+00, -3.7505e+00, -2.9349e+00],\n",
       "         [ 6.3078e+00, -3.0557e+00, -3.3462e+00],\n",
       "         [ 6.3697e+00, -3.6102e+00, -3.3413e+00],\n",
       "         [ 6.4227e+00, -3.1592e+00, -3.6249e+00],\n",
       "         [ 6.5241e+00, -3.5238e+00, -3.3270e+00],\n",
       "         [ 5.6972e+00, -3.0654e+00, -3.2117e+00],\n",
       "         [ 1.2422e+00,  7.4736e-01, -2.2911e+00],\n",
       "         [ 2.3217e+00, -1.6614e+00, -1.1577e+00],\n",
       "         [ 4.7936e+00, -3.8560e+00, -1.4367e+00],\n",
       "         [ 5.4996e-01,  2.0828e+00, -2.0964e+00],\n",
       "         [ 6.0901e+00, -3.3917e+00, -3.0569e+00],\n",
       "         [ 6.3119e+00, -2.9549e+00, -3.1842e+00],\n",
       "         [ 6.0713e+00, -3.0487e+00, -3.4161e+00],\n",
       "         [ 6.4081e+00, -2.8874e+00, -3.5440e+00],\n",
       "         [ 6.3659e+00, -3.2684e+00, -3.0713e+00],\n",
       "         [ 6.2450e+00, -2.5336e+00, -3.8563e+00],\n",
       "         [ 5.6829e+00, -2.5456e+00, -3.3678e+00],\n",
       "         [ 6.3260e+00, -3.0664e+00, -3.4163e+00],\n",
       "         [ 1.5836e+00,  1.6655e+00, -3.2458e+00],\n",
       "         [ 6.8530e+00, -2.6434e+00, -3.9426e+00],\n",
       "         [ 4.7672e+00, -2.0307e+00, -3.1241e+00],\n",
       "         [ 4.9757e+00, -2.2271e+00, -2.9800e+00],\n",
       "         [ 2.5168e+00, -8.4455e-01, -2.0169e+00],\n",
       "         [ 4.8914e+00, -2.0964e+00, -2.9447e+00],\n",
       "         [ 4.9148e+00, -2.0511e+00, -3.0197e+00],\n",
       "         [ 1.4916e+00,  3.1224e-01, -1.9404e+00],\n",
       "         [ 6.2005e-01, -1.7710e+00,  4.8282e-01],\n",
       "         [ 1.2203e+00, -1.9232e+00, -8.3640e-04],\n",
       "         [ 2.1594e+00, -1.7948e+00, -8.7022e-01],\n",
       "         [ 3.2903e+00, -1.4171e+00, -2.0703e+00],\n",
       "         [ 3.1740e+00, -1.3263e+00, -1.9914e+00],\n",
       "         [ 2.9296e+00, -8.9886e-01, -2.1722e+00],\n",
       "         [ 3.8649e+00, -1.2717e+00, -2.8564e+00],\n",
       "         [ 1.9993e+00, -3.7953e-01, -1.9628e+00],\n",
       "         [ 1.3824e-01,  1.6354e-01, -8.1141e-01],\n",
       "         [-4.7216e-02,  2.0317e-01, -5.8316e-01],\n",
       "         [ 3.3553e-02, -9.8253e-01,  3.3878e-01],\n",
       "         [ 4.5110e-01, -1.8480e+00,  9.1635e-01],\n",
       "         [ 8.8800e-01, -1.8002e+00,  5.3948e-01],\n",
       "         [ 1.5496e+00, -1.9510e+00,  2.4363e-01],\n",
       "         [ 2.7614e+00, -2.1719e+00, -6.5723e-01],\n",
       "         [ 3.6462e+00, -1.6333e+00, -1.8244e+00],\n",
       "         [ 3.6126e+00, -1.1411e+00, -2.5491e+00],\n",
       "         [ 2.8521e+00, -7.6679e-01, -2.3068e+00],\n",
       "         [ 2.5973e+00, -7.6213e-01, -2.0883e+00],\n",
       "         [ 2.2535e+00, -5.0092e-01, -1.9946e+00],\n",
       "         [ 1.7030e+00, -8.2884e-01, -1.3991e+00],\n",
       "         [ 1.1008e+00, -9.5326e-01, -7.2141e-01],\n",
       "         [ 4.0709e+00, -1.7507e+00, -2.4944e+00],\n",
       "         [ 2.7178e+00, -1.5657e+00, -1.5661e+00],\n",
       "         [ 6.8513e-01,  9.8927e-01, -1.4460e+00],\n",
       "         [ 1.1119e+00,  6.0443e-01, -1.7226e+00],\n",
       "         [-1.8122e-01, -1.4387e+00,  1.2637e+00],\n",
       "         [ 1.6284e-01, -1.4823e+00,  7.5347e-01],\n",
       "         [ 1.3713e+00, -1.9870e+00, -1.4336e-01],\n",
       "         [ 2.0637e+00, -1.9539e+00, -7.2451e-01],\n",
       "         [ 2.4408e+00, -1.9219e+00, -8.6586e-01],\n",
       "         [ 3.3891e+00, -1.6999e+00, -1.9411e+00],\n",
       "         [ 2.4633e+00, -8.0658e-01, -2.0411e+00],\n",
       "         [ 4.4175e+00, -1.8043e+00, -2.9296e+00],\n",
       "         [ 1.3471e+00,  1.7046e-01, -1.7619e+00],\n",
       "         [-4.1012e-01,  8.7659e-01, -7.6603e-01],\n",
       "         [ 8.9561e-02,  1.9756e-01, -7.2576e-01],\n",
       "         [ 6.4454e-02, -2.4560e-01, -3.8097e-01],\n",
       "         [ 2.1547e-01, -1.6734e+00,  8.8936e-01],\n",
       "         [ 6.2458e-01, -1.8721e+00,  8.0483e-01],\n",
       "         [ 1.1062e+00, -1.7916e+00,  5.7335e-01],\n",
       "         [ 3.2081e+00, -2.1305e+00, -1.0843e+00],\n",
       "         [ 4.0197e+00, -1.8503e+00, -2.2219e+00],\n",
       "         [ 4.0134e+00, -1.5567e+00, -2.5115e+00],\n",
       "         [ 3.3441e+00, -1.0500e+00, -2.4102e+00],\n",
       "         [ 2.8274e+00, -9.4724e-01, -2.1446e+00],\n",
       "         [ 1.8423e+00, -2.8877e-02, -1.9581e+00],\n",
       "         [ 4.6055e+00, -1.9868e+00, -2.7741e+00],\n",
       "         [ 1.5432e+00, -1.2260e+00, -8.4631e-01],\n",
       "         [ 1.7334e+00, -9.9165e-01, -1.2997e+00],\n",
       "         [ 4.2645e+00, -1.8630e+00, -2.5677e+00],\n",
       "         [ 2.1173e+00, -1.2529e+00, -1.1810e+00],\n",
       "         [ 4.3564e+00, -1.9559e+00, -2.5302e+00],\n",
       "         [ 7.7639e-01,  8.4676e-01, -1.4935e+00],\n",
       "         [ 8.3093e-01,  7.6703e-01, -1.5505e+00],\n",
       "         [ 2.6739e+00, -1.7425e+00, -1.2004e+00],\n",
       "         [ 1.2140e+00, -1.7641e+00, -4.2867e-02],\n",
       "         [ 8.7246e-01, -1.5983e+00,  6.8829e-02],\n",
       "         [ 1.7961e+00, -1.8649e+00, -5.1021e-01],\n",
       "         [ 2.1065e+00, -1.7850e+00, -7.1384e-01],\n",
       "         [ 3.0117e+00, -1.0146e+00, -2.0569e+00],\n",
       "         [ 5.0438e+00, -2.0619e+00, -3.1338e+00],\n",
       "         [ 2.6868e+00, -1.3692e+00, -1.5784e+00],\n",
       "         [ 3.3843e+00, -1.3505e+00, -2.5710e+00],\n",
       "         [ 1.2769e+00,  1.9668e-01, -1.7226e+00],\n",
       "         [-3.4155e-01,  3.6790e-01, -4.2342e-01],\n",
       "         [ 1.5270e+00, -7.5970e-01, -1.0298e+00],\n",
       "         [-1.3988e-02, -6.9354e-01,  3.2239e-01],\n",
       "         [ 3.7412e-01, -1.8422e+00,  1.0150e+00],\n",
       "         [ 1.2168e+00, -1.9803e+00,  3.5675e-01],\n",
       "         [ 3.0585e+00, -2.3020e+00, -8.1778e-01],\n",
       "         [ 3.9744e+00, -1.8118e+00, -2.2636e+00],\n",
       "         [ 4.2693e+00, -1.4121e+00, -2.9346e+00],\n",
       "         [ 3.0445e+00, -1.0286e+00, -2.2413e+00],\n",
       "         [ 2.6140e+00, -8.1950e-01, -2.0158e+00],\n",
       "         [ 2.1632e+00, -3.6743e-01, -2.0629e+00],\n",
       "         [ 4.2002e+00, -1.8103e+00, -2.5019e+00],\n",
       "         [ 4.9019e+00, -2.1576e+00, -2.9160e+00],\n",
       "         [ 4.8899e+00, -2.2516e+00, -2.8278e+00],\n",
       "         [ 2.5923e+00, -5.5541e-01, -2.4997e+00],\n",
       "         [ 4.7423e+00, -2.1264e+00, -2.8415e+00],\n",
       "         [ 4.5321e+00, -1.9796e+00, -2.6977e+00],\n",
       "         [ 2.7827e+00, -8.2017e-01, -2.2660e+00],\n",
       "         [ 3.7368e+00, -1.3592e+00, -2.6275e+00],\n",
       "         [ 1.8750e+00,  4.8458e-02, -2.2690e+00],\n",
       "         [ 1.8886e+00,  1.4454e-01, -2.3249e+00]]], device='mps:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f2f7790",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=[-1] * 128\n",
    "arr\n",
    "\n",
    "for item in sentiments:\n",
    "    pos=item[\"pos\"]\n",
    "    start = pos[0]\n",
    "    end = pos[0]+pos[1]\n",
    "    arr[start:end] = [item[\"senti\"]] * (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "838e4123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2],\n",
       " [8, 8],\n",
       " [12, 12],\n",
       " [25, 25],\n",
       " [34, 34],\n",
       " [50, 50],\n",
       " [51, 53],\n",
       " [66, 66],\n",
       " [77, 77],\n",
       " [78, 78],\n",
       " [95, 95],\n",
       " [107, 107]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c3fdf2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B-ASP',\n",
       " 'I-ASP',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ASP',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ASP',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ASP',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ASP',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ASP',\n",
       " 'B-ASP',\n",
       " 'I-ASP',\n",
       " 'I-ASP',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ASP',\n",
       " 'O',\n",
       " 'I-ASP',\n",
       " 'I-ASP',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ASP',\n",
       " 'B-ASP',\n",
       " 'O',\n",
       " 'I-ASP',\n",
       " 'I-ASP',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ASP',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ASP',\n",
       " 'O',\n",
       " 'I-ASP',\n",
       " 'I-ASP',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [id2label[label] for label in preds.tolist()]\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a91b9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "BIO Tag",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Word",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sentiment",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "d7044c49-e00e-4202-9986-9a7b8ff3bd10",
       "rows": [
        [
         "0",
         "B-ASP",
         "car",
         "positive"
        ],
        [
         "1",
         "I-ASP",
         "quality",
         "positive"
        ],
        [
         "2",
         "O",
         "is",
         ""
        ],
        [
         "3",
         "O",
         "very",
         ""
        ],
        [
         "4",
         "O",
         "nice",
         ""
        ],
        [
         "5",
         "O",
         "but",
         ""
        ],
        [
         "6",
         "O",
         "the",
         ""
        ],
        [
         "7",
         "B-ASP",
         "controller",
         "negative"
        ],
        [
         "8",
         "O",
         "sucks",
         ""
        ],
        [
         "9",
         "O",
         ".",
         ""
        ],
        [
         "10",
         "O",
         "the",
         ""
        ],
        [
         "11",
         "B-ASP",
         "controller",
         "negative"
        ],
        [
         "12",
         "O",
         "of",
         ""
        ],
        [
         "13",
         "O",
         "this",
         ""
        ],
        [
         "14",
         "O",
         "car",
         ""
        ],
        [
         "15",
         "O",
         "do",
         ""
        ],
        [
         "16",
         "O",
         "not",
         ""
        ],
        [
         "17",
         "O",
         "works",
         ""
        ],
        [
         "18",
         "O",
         "properly",
         ""
        ],
        [
         "19",
         "O",
         "and",
         ""
        ],
        [
         "20",
         "O",
         "the",
         ""
        ],
        [
         "21",
         "O",
         "final",
         ""
        ],
        [
         "22",
         "O",
         "in",
         ""
        ],
        [
         "23",
         "O",
         "the",
         ""
        ],
        [
         "24",
         "B-ASP",
         "controller",
         "negative"
        ],
        [
         "25",
         "O",
         "do",
         ""
        ],
        [
         "26",
         "O",
         "not",
         ""
        ],
        [
         "27",
         "O",
         "rotate",
         ""
        ],
        [
         "28",
         "O",
         "fully",
         ""
        ],
        [
         "29",
         "O",
         "it",
         ""
        ],
        [
         "30",
         "O",
         "only",
         ""
        ],
        [
         "31",
         "O",
         "rotate",
         ""
        ],
        [
         "32",
         "O",
         "like",
         ""
        ],
        [
         "33",
         "B-ASP",
         "button",
         "negative"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 34
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BIO Tag</th>\n",
       "      <th>Word</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-ASP</td>\n",
       "      <td>car</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I-ASP</td>\n",
       "      <td>quality</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O</td>\n",
       "      <td>is</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O</td>\n",
       "      <td>very</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O</td>\n",
       "      <td>nice</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>O</td>\n",
       "      <td>but</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>O</td>\n",
       "      <td>the</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B-ASP</td>\n",
       "      <td>controller</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>O</td>\n",
       "      <td>sucks</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>O</td>\n",
       "      <td>.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>O</td>\n",
       "      <td>the</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B-ASP</td>\n",
       "      <td>controller</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>O</td>\n",
       "      <td>of</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>O</td>\n",
       "      <td>this</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>O</td>\n",
       "      <td>car</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>O</td>\n",
       "      <td>do</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>O</td>\n",
       "      <td>not</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>O</td>\n",
       "      <td>works</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>O</td>\n",
       "      <td>properly</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>O</td>\n",
       "      <td>and</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>O</td>\n",
       "      <td>the</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>O</td>\n",
       "      <td>final</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>O</td>\n",
       "      <td>in</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>O</td>\n",
       "      <td>the</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>B-ASP</td>\n",
       "      <td>controller</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>O</td>\n",
       "      <td>do</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>O</td>\n",
       "      <td>not</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>O</td>\n",
       "      <td>rotate</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>O</td>\n",
       "      <td>fully</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>O</td>\n",
       "      <td>it</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>O</td>\n",
       "      <td>only</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>O</td>\n",
       "      <td>rotate</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>O</td>\n",
       "      <td>like</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>B-ASP</td>\n",
       "      <td>button</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BIO Tag        Word Sentiment\n",
       "0    B-ASP         car  positive\n",
       "1    I-ASP     quality  positive\n",
       "2        O          is          \n",
       "3        O        very          \n",
       "4        O        nice          \n",
       "5        O         but          \n",
       "6        O         the          \n",
       "7    B-ASP  controller  negative\n",
       "8        O       sucks          \n",
       "9        O           .          \n",
       "10       O         the          \n",
       "11   B-ASP  controller  negative\n",
       "12       O          of          \n",
       "13       O        this          \n",
       "14       O         car          \n",
       "15       O          do          \n",
       "16       O         not          \n",
       "17       O       works          \n",
       "18       O    properly          \n",
       "19       O         and          \n",
       "20       O         the          \n",
       "21       O       final          \n",
       "22       O          in          \n",
       "23       O         the          \n",
       "24   B-ASP  controller  negative\n",
       "25       O          do          \n",
       "26       O         not          \n",
       "27       O      rotate          \n",
       "28       O       fully          \n",
       "29       O          it          \n",
       "30       O        only          \n",
       "31       O      rotate          \n",
       "32       O        like          \n",
       "33   B-ASP      button  negative"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def print_sentiment(bio_tag, sentiment):\n",
    "    if(bio_tag in [\"B-ASP\", \"I-ASP\"]):\n",
    "        return id2sentiment[sentiment]\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "rows = []\n",
    "\n",
    "for item in zip(predictions, temp[\"input_ids\"], arr):\n",
    "    word = tokenizer.convert_ids_to_tokens(item[1])\n",
    "    if word in ['[CLS]', '[SEP]', '[PAD]']:\n",
    "        continue\n",
    "    sentiment = print_sentiment(item[0], item[2])\n",
    "    rows.append({\n",
    "        \"BIO Tag\": item[0],\n",
    "        \"Word\": word,\n",
    "        \"Sentiment\": sentiment\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "09a1dc49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table border=\"1\" class=\"dataframe\">  <thead>    <tr style=\"text-align: right;\">      <th>BIO Tag</th>      <th>Word</th>      <th>Sentiment</th>    </tr>  </thead>  <tbody>    <tr>      <td>B-ASP</td>      <td>car</td>      <td>positive</td>    </tr>    <tr>      <td>I-ASP</td>      <td>quality</td>      <td>positive</td>    </tr>    <tr>      <td>O</td>      <td>is</td>      <td></td>    </tr>    <tr>      <td>O</td>      <td>very</td>      <td></td>    </tr>    <tr>      <td>O</td>      <td>nice</td>      <td></td>    </tr>    <tr>      <td>O</td>      <td>but</td>      <td></td>    </tr>    <tr>      <td>O</td>      <td>the</td>      <td></td>    </tr>    <tr>      <td>B-ASP</td>      <td>controller</td>      <td>negative</td>    </tr>    <tr>      <td>O</td>      <td>sucks</td>      <td></td>    </tr>    <tr>      <td>O</td>      <td>.</td>      <td></td>    </tr>    <tr>      <td>O</td>      <td>the</td>      <td></td>    </tr>    <tr>      <td>B-ASP</td>      <td>controller</td>      <td>negative</td>    </tr>    <tr>      <td>O</td>      <td>of</td>      <td></td>    </tr>    <tr>      <td>O</td>      <td>this</td>      <td></td>    </tr>    <tr>      <td>O</td>      <td>car</td>      <td></td>    </tr>    <tr>      <td>O</td>      <td>do</td>      <td></td>    </tr>    <tr>      <td>O</td>      <td>not</td>      <td></td>    </tr>    <tr>      <td>O</td>      <td>works</td>      <td></td>    </tr>    <tr>      <td>O</td>      <td>properly</td>      <td></td>    </tr>    <tr>      <td>O</td>      <td>and</td>      <td></td>    </tr>    <tr>      <td>O</td>      <td>the</td>      <td></td>    </tr>    <tr>      <td>O</td>      <td>final</td>      <td></td>    </tr>    <tr>      <td>O</td>      <td>in</td>      <td></td>    </tr>    <tr>      <td>O</td>      <td>the</td>      <td></td>    </tr>    <tr>      <td>B-ASP</td>      <td>controller</td>      <td>negative</td>    </tr>    <tr>      <td>O</td>      <td>do</td>      <td></td>    </tr>    <tr>      <td>O</td>      <td>not</td>      <td></td>    </tr>    <tr>      <td>O</td>      <td>rotate</td>      <td></td>    </tr>    <tr>      <td>O</td>      <td>fully</td>      <td></td>    </tr>    <tr>      <td>O</td>      <td>it</td>      <td></td>    </tr>    <tr>      <td>O</td>      <td>only</td>      <td></td>    </tr>    <tr>      <td>O</td>      <td>rotate</td>      <td></td>    </tr>    <tr>      <td>O</td>      <td>like</td>      <td></td>    </tr>    <tr>      <td>B-ASP</td>      <td>button</td>      <td>negative</td>    </tr>  </tbody></table>'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_html(index=False).replace(\"\\n\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cc06e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chrome', (2, 2)), ('book', (3, 3))]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_aspects(input_ids, predictions, tokenizer):\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "    \n",
    "    aspects = []\n",
    "    current_aspect = []\n",
    "    current_position = []\n",
    "    current_idx = 0\n",
    "\n",
    "    for idx, (token, label) in enumerate(zip(tokens, predictions[0])):\n",
    "        if token in [tokenizer.cls_token, tokenizer.sep_token, tokenizer.pad_token]:\n",
    "            continue\n",
    "            \n",
    "        label_tag = id2label.get(label, \"O\")\n",
    "        \n",
    "        if label_tag == \"B-ASP\":\n",
    "            if current_aspect:\n",
    "                aspects.append((\" \".join(current_aspect), (current_position[0], current_position[-1])))\n",
    "            current_aspect = [token]\n",
    "            current_position = [idx]\n",
    "        elif label_tag == \"I-ASP\" and current_aspect:\n",
    "            current_aspect.append(token)\n",
    "            current_position.append(idx)\n",
    "        else:\n",
    "            if current_aspect:\n",
    "                aspects.append((\" \".join(current_aspect), (current_position[0], current_position[-1])))\n",
    "                current_aspect = []\n",
    "                current_position = []\n",
    "\n",
    "    if current_aspect:\n",
    "        aspects.append((\" \".join(current_aspect), (current_position[0], current_position[-1])))\n",
    "\n",
    "    clean_aspects = []\n",
    "    for aspect, pos in aspects:\n",
    "        cleaned = \"\"\n",
    "        for word in aspect.split():\n",
    "            if word.startswith(\"##\"):\n",
    "                cleaned += word[2:]  # Remove ## prefix\n",
    "            else:\n",
    "                if cleaned:\n",
    "                    cleaned += \" \"\n",
    "                cleaned += word\n",
    "        clean_aspects.append((cleaned, pos))\n",
    "\n",
    "    return clean_aspects\n",
    "\n",
    "\n",
    "extracted_aspects = extract_aspects(input_ids, predictions, tokenizer)\n",
    "extracted_aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed2406b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
